
Exercise




Installation

git clone https://github.com/alxxthegeek/aiven_kafka_demo.git
cd aiven_kafka_demo
pip3 install -r requirements.txt


How to use

open two windows
1. python3 metrics_producer.py
2. python3 metrics_consumer.py

PostgreSQL schema

Database kaf_demo
Table system_metrics

CREATE TABLE public.system_metrics (
    id SERIAL NOT NULL,
    datetime timestamp without time zone,
    hostname character varying(64) NOT NULL,
    metric character varying(64) NOT NULL,
    value real NOT NULL,
    CONSTRAINT sys_metrics_prikey PRIMARY KEY (id)
);


select * from system_metrics ORDER BY datetime DESC LIMIT 40;
+----+--------------------------+--------+---------------------+----------+
|id  |datetime                  |hostname|metric               |value     |
+----+--------------------------+--------+---------------------+----------+
|1800|2020-02-10 15:00:09.644000|kaf     |total_cpu            |3.2       |
|1796|2020-02-10 14:59:59.394000|kaf     |percent_memory_use   |65.9      |
|1795|2020-02-10 14:59:59.394000|kaf     |available_memory     |685416450 |
|1797|2020-02-10 14:59:59.394000|kaf     |network_traffic_in   |366120896 |
|1793|2020-02-10 14:59:59.394000|kaf     |current_cpu_frequency|3092.839  |
|1794|2020-02-10 14:59:59.394000|kaf     |memory_use           |2009927680|
|1792|2020-02-10 14:59:59.394000|kaf     |total_cpu            |2.9       |
|1798|2020-02-10 14:59:59.394000|kaf     |network_traffic_out  |366120896 |
|1799|2020-02-10 14:59:59.394000|kaf     |total_network_traffic|904035200 |
|1789|2020-02-10 14:59:49.130000|kaf     |network_traffic_in   |366112992 |
|1788|2020-02-10 14:59:49.130000|kaf     |percent_memory_use   |65.9      |
|1787|2020-02-10 14:59:49.130000|kaf     |available_memory     |685395970 |
|1791|2020-02-10 14:59:49.130000|kaf     |total_network_traffic|904019520 |
|1790|2020-02-10 14:59:49.130000|kaf     |network_traffic_out  |366112992 |
|1784|2020-02-10 14:59:49.130000|kaf     |total_cpu            |2.1       |
|1786|2020-02-10 14:59:49.130000|kaf     |memory_use           |2009927680|
|1785|2020-02-10 14:59:49.130000|kaf     |current_cpu_frequency|3092.839  |
|1780|2020-02-10 14:59:38.885000|kaf     |percent_memory_use   |65.9      |
|1781|2020-02-10 14:59:38.885000|kaf     |network_traffic_in   |366103136 |
|1779|2020-02-10 14:59:38.885000|kaf     |available_memory     |685379580 |
|1782|2020-02-10 14:59:38.885000|kaf     |network_traffic_out  |366103136 |
|1777|2020-02-10 14:59:38.885000|kaf     |current_cpu_frequency|3092.839  |
|1783|2020-02-10 14:59:38.885000|kaf     |total_network_traffic|904000190 |
|1776|2020-02-10 14:59:38.885000|kaf     |total_cpu            |1.8       |
|1778|2020-02-10 14:59:38.885000|kaf     |memory_use           |2009927680|
|1774|2020-02-10 14:59:28.641000|kaf     |network_traffic_out  |366095168 |
|1770|2020-02-10 14:59:28.641000|kaf     |memory_use           |2009927680|
|1769|2020-02-10 14:59:28.641000|kaf     |current_cpu_frequency|3092.839  |
|1771|2020-02-10 14:59:28.641000|kaf     |available_memory     |685363200 |
|1772|2020-02-10 14:59:28.641000|kaf     |percent_memory_use   |65.9      |
|1775|2020-02-10 14:59:28.641000|kaf     |total_network_traffic|903984130 |
|1773|2020-02-10 14:59:28.641000|kaf     |network_traffic_in   |366095168 |
|1768|2020-02-10 14:59:28.641000|kaf     |total_cpu            |2.6       |
|1765|2020-02-10 14:59:18.399000|kaf     |network_traffic_in   |366087264 |
|1766|2020-02-10 14:59:18.399000|kaf     |network_traffic_out  |366087264 |
|1763|2020-02-10 14:59:18.399000|kaf     |available_memory     |685355010 |
|1762|2020-02-10 14:59:18.399000|kaf     |memory_use           |2009927680|
|1764|2020-02-10 14:59:18.399000|kaf     |percent_memory_use   |65.9      |
|1760|2020-02-10 14:59:18.399000|kaf     |total_cpu            |2.6       |
|1767|2020-02-10 14:59:18.399000|kaf     |total_network_traffic|903968770 |
+----+--------------------------+--------+---------------------+----------+



Discussion

Logs are stored into
../kaf_demo/logs

Please note the logging is currently set to debug which will produce an excessive amount of log entries but is useful when learning how a
system works(as I've never used kafka before).
Logging code is from previous projects of mine(pretty simple).

Implementation is using a single producer and single consumer.
Performance could be improved by  implementing a separate producer for each metric type and a separate consumer using threads.
A threaded alternative to metrics.prod.py is metrics_producer.py. In this implementation it does not provide any benefits.

In the producer used the python-kafka serializer as I saw it in an example(medium article) and decided to use it.

Only eight metrics were implemented - total cpu %, current cpu frequency (GHz), memory use(Total memory usage), percent memory use(%),
network traffic in (bytes received), network traffic out(bytes sent) and total network traffic(bytes received and sent).
Used psutils as it works on all platforms, I have used it before and it is easy to get it up and running.

I used the pyscopg2 library for the postgres access.

I tried to use the pyscopg2.extra.execute_values but was getting tuple errors that I could not fix in the time I set myself
so reverted to using a loop and saving each metric from the message separately. Not optimal/in-efficient.

No recovery from errors is implemented.If an error or exception occurs the system will exit.

The table schema is simple(naive) for ease/speed of implementation and is fairly wasteful. It does not record the metric type or
type of units. A more optimal solution would be a table per metric

The solution is manually deployed.
A better solution would have been to setup the project in a virtual env and then deploy the virtual env via pip.
















